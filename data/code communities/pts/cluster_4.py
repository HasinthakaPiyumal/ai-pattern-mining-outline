# Cluster 4

def main():
    """Main entry point for the CLI."""
    args = parse_args()
    if args.command == 'run':
        if hasattr(args, 'generate_thought_anchors') and args.generate_thought_anchors:
            run_thought_anchors(args)
        else:
            run_pts(args)
    elif args.command == 'export':
        export_tokens(args)
    elif args.command == 'push':
        push_to_hf(args)
    else:
        print('Please specify a command: run, export, or push')
        sys.exit(1)

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description='Pivotal Token Search (PTS)')
    subparsers = parser.add_subparsers(dest='command', help='Sub-command to run')
    run_parser = subparsers.add_parser('run', help='Run PTS on a dataset')
    run_parser.add_argument('--model', type=str, required=True, help='Model name or path')
    run_parser.add_argument('--dataset', type=str, default='codelion/optillmbench', help='Dataset name or path')
    run_parser.add_argument('--config', type=str, default=None, help='Dataset configuration name (if applicable)')
    run_parser.add_argument('--split', type=str, default='train', help='Dataset split to use')
    run_parser.add_argument('--output-path', type=str, default='pivotal_tokens.jsonl', help='Output file path')
    run_parser.add_argument('--device', type=str, default=None, help='Device to run on (cuda, cpu)')
    run_parser.add_argument('--prob-threshold', type=float, default=0.2, help='Probability threshold for pivotal tokens')
    run_parser.add_argument('--temperature', type=float, default=0.6, help='Temperature for sampling')
    run_parser.add_argument('--top-p', type=float, default=0.95, help='Top-p (nucleus) sampling parameter')
    run_parser.add_argument('--top-k', type=int, default=20, help='Top-k sampling parameter')
    run_parser.add_argument('--min-p', type=float, default=0.0, help='Min-p sampling parameter')
    run_parser.add_argument('--max-new-tokens', type=int, default=512, help='Maximum number of new tokens to generate')
    run_parser.add_argument('--num-samples', type=int, default=50, help='Number of samples for probability estimation')
    run_parser.add_argument('--batch-size', type=int, default=5, help='Batch size for generation')
    run_parser.add_argument('--sample-size', type=int, default=None, help='Number of examples to sample from dataset')
    run_parser.add_argument('--max-examples', type=int, default=100, help='Maximum number of examples to process')
    run_parser.add_argument('--max-generations', type=int, default=10, help='Maximum number of generations per example')
    run_parser.add_argument('--min-prob', type=float, default=0.2, help='Minimum initial success probability')
    run_parser.add_argument('--max-prob', type=float, default=0.8, help='Maximum initial success probability')
    run_parser.add_argument('--seed', type=int, default=42, help='Random seed')
    run_parser.add_argument('--system-prompt', type=str, default=None, help='System prompt for chat models')
    run_parser.add_argument('--query-key', type=str, default=None, help="Key for query field in dataset (e.g., 'question', 'instruction', 'problem'). Auto-detected if not specified.")
    run_parser.add_argument('--answer-key', type=str, default=None, help="Key for answer field in dataset (e.g., 'answer', 'output', 'solution'). Auto-detected if not specified.")
    run_parser.add_argument('--log-level', type=str, default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], help='Logging level')
    run_parser.add_argument('--debug', action='store_true', help='Enable debug mode to print questions and responses')
    run_parser.add_argument('--generate-thought-anchors', action='store_true', help='Generate thought anchors dataset instead of pivotal tokens')
    run_parser.add_argument('--skip-embeddings', action='store_true', help='Skip embedding generation for faster processing (thought anchors only)')
    export_parser = subparsers.add_parser('export', help='Export tokens to different formats')
    export_parser.add_argument('--input-path', type=str, required=True, help='Input tokens file path')
    export_parser.add_argument('--output-path', type=str, required=True, help='Output file path')
    export_parser.add_argument('--format', type=str, required=True, choices=['dpo', 'steering', 'thought_anchors'], help='Export format')
    export_parser.add_argument('--model', type=str, default=None, help='Model name or path (required for steering)')
    export_parser.add_argument('--min-prob-delta', type=float, default=0.1, help='Minimum probability delta')
    export_parser.add_argument('--balance', action='store_true', help='Balance positive and negative examples')
    export_parser.add_argument('--max-pairs', type=int, default=None, help='Maximum number of pairs to export')
    export_parser.add_argument('--seed', type=int, default=42, help='Random seed')
    export_parser.add_argument('--save-tokens', action='store_true', help='Save updated tokens')
    export_parser.add_argument('--tokens-output-path', type=str, default=None, help='Path to save updated tokens')
    export_parser.add_argument('--num-candidates', type=int, default=10, help='Number of candidate tokens')
    export_parser.add_argument('--find-rejected-tokens', action='store_true', help='Find rejected tokens')
    export_parser.add_argument('--layer-nums', type=int, nargs='+', default=[19, 23, 27], help='Layer numbers for steering')
    export_parser.add_argument('--num-clusters', type=int, default=10, help='Number of clusters for steering')
    export_parser.add_argument('--pca-components', type=int, default=50, help='Number of PCA components')
    export_parser.add_argument('--batch-size', type=int, default=4, help='Batch size for steering')
    export_parser.add_argument('--select-layer', type=int, default=None, help='Layer to use for steering')
    export_parser.add_argument('--hf-push', action='store_true', help='Push to Hugging Face')
    export_parser.add_argument('--hf-repo-id', type=str, default=None, help='Hugging Face repository ID')
    export_parser.add_argument('--private', action='store_true', help='Make Hugging Face repository private')
    export_parser.add_argument('--log-level', type=str, default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], help='Logging level')
    push_parser = subparsers.add_parser('push', help='Push a file to Hugging Face')
    push_parser.add_argument('--input-path', type=str, required=True, help='Input file path')
    push_parser.add_argument('--hf-repo-id', type=str, required=True, help='Hugging Face repository ID')
    push_parser.add_argument('--private', action='store_true', help='Make Hugging Face repository private')
    push_parser.add_argument('--no-readme', action='store_true', help='Skip creating a README file')
    push_parser.add_argument('--model', type=str, default=None, help='Model name for README')
    push_parser.add_argument('--log-level', type=str, default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], help='Logging level')
    return parser.parse_args()

