# Cluster 97

def test_fpn_normal():
    outs = fpn_neck_config('fpn_normal')
    ort_validate(*outs)

def fpn_neck_config(test_step_name):
    """Return the class containing the corresponding attributes according to
    the fpn_test_step_names."""
    s = 64
    in_channels = [8, 16, 32, 64]
    feat_sizes = [s // 2 ** i for i in range(4)]
    out_channels = 8
    feats = [torch.rand(1, in_channels[i], feat_sizes[i], feat_sizes[i]) for i in range(len(in_channels))]
    if fpn_test_step_names[test_step_name] == 0:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs=True, num_outs=5)
    elif fpn_test_step_names[test_step_name] == 1:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs=False, num_outs=5)
    elif fpn_test_step_names[test_step_name] == 2:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs=True, no_norm_on_lateral=False, norm_cfg=dict(type='BN', requires_grad=True), num_outs=5)
    elif fpn_test_step_names[test_step_name] == 3:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs=True, upsample_cfg=dict(mode='bilinear', align_corners=True), num_outs=5)
    elif fpn_test_step_names[test_step_name] == 4:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs=True, upsample_cfg=dict(scale_factor=2), num_outs=5)
    elif fpn_test_step_names[test_step_name] == 5:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs='on_input', num_outs=5)
    elif fpn_test_step_names[test_step_name] == 6:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs='on_lateral', num_outs=5)
    elif fpn_test_step_names[test_step_name] == 7:
        fpn_model = FPN(in_channels=in_channels, out_channels=out_channels, add_extra_convs='on_output', num_outs=5)
    return (fpn_model, feats)

def ort_validate(model, feats, onnx_io='tmp.onnx'):
    """Validate the output of the onnxruntime backend is the same as the output
    generated by torch.

    Args:
        model (nn.Module | function): the function of model or model
            to be verified.
        feats (tuple(list(torch.Tensor)) | list(torch.Tensor) | torch.Tensor):
            the input of model.
        onnx_io (str): the name of onnx output file.
    """
    if isinstance(model, nn.Module):
        wrap_model = model
    else:
        wrap_model = WrapFunction(model)
    wrap_model.cpu().eval()
    with torch.no_grad():
        torch.onnx.export(wrap_model, feats, onnx_io, export_params=True, keep_initializers_as_inputs=True, do_constant_folding=True, verbose=False, opset_version=11)
    if isinstance(feats, tuple):
        ort_feats = []
        for feat in feats:
            ort_feats += feat
    else:
        ort_feats = feats
    onnx_outputs = get_ort_model_output(ort_feats)
    if osp.exists(onnx_io):
        os.remove(onnx_io)
    if isinstance(feats, tuple):
        torch_outputs = convert_result_list(wrap_model.forward(*feats))
    else:
        torch_outputs = convert_result_list(wrap_model.forward(feats))
    torch_outputs = [torch_output.detach().numpy() for torch_output in torch_outputs]
    for i in range(len(onnx_outputs)):
        np.testing.assert_allclose(torch_outputs[i], onnx_outputs[i], rtol=0.001, atol=1e-05)

def test_fpn_wo_extra_convs():
    outs = fpn_neck_config('fpn_wo_extra_convs')
    ort_validate(*outs)

def test_fpn_lateral_bns():
    outs = fpn_neck_config('fpn_lateral_bns')
    ort_validate(*outs)

def test_fpn_bilinear_upsample():
    outs = fpn_neck_config('fpn_bilinear_upsample')
    ort_validate(*outs)

def test_fpn_scale_factor():
    outs = fpn_neck_config('fpn_scale_factor')
    ort_validate(*outs)

def test_fpn_extra_convs_inputs():
    outs = fpn_neck_config('fpn_extra_convs_inputs')
    ort_validate(*outs)

def test_fpn_extra_convs_laterals():
    outs = fpn_neck_config('fpn_extra_convs_laterals')
    ort_validate(*outs)

def test_fpn_extra_convs_outputs():
    outs = fpn_neck_config('fpn_extra_convs_outputs')
    ort_validate(*outs)

def test_yolo_normal():
    outs = yolo_neck_config('yolo_normal')
    ort_validate(*outs)

def yolo_neck_config(test_step_name):
    """Config yolov3 Neck."""
    in_channels = [16, 8, 4]
    out_channels = [8, 4, 2]
    yolov3_neck_data = 'yolov3_neck.pkl'
    feats = mmcv.load(osp.join(data_path, yolov3_neck_data))
    if yolo_test_step_names[test_step_name] == 0:
        yolo_model = YOLOV3Neck(in_channels=in_channels, out_channels=out_channels, num_scales=3)
    return (yolo_model, feats)

def test_retina_head_forward_single():
    """Test RetinaNet Head single forward in torch and onnxruntime env."""
    retina_model = retinanet_config()
    feat = torch.rand(1, retina_model.in_channels, 32, 32)
    ort_validate(retina_model.forward_single, feat)

def retinanet_config():
    """RetinanNet Head Config."""
    head_cfg = dict(stacked_convs=6, feat_channels=2, anchor_generator=dict(type='AnchorGenerator', octave_base_scale=4, scales_per_octave=3, ratios=[0.5, 1.0, 2.0], strides=[8, 16, 32, 64, 128]), bbox_coder=dict(type='DeltaXYWHBBoxCoder', target_means=[0.0, 0.0, 0.0, 0.0], target_stds=[1.0, 1.0, 1.0, 1.0]))
    test_cfg = mmcv.Config(dict(deploy_nms_pre=0, min_bbox_size=0, score_thr=0.05, nms=dict(type='nms', iou_threshold=0.5), max_per_img=100))
    model = RetinaHead(num_classes=4, in_channels=1, test_cfg=test_cfg, **head_cfg)
    model.requires_grad_(False)
    return model

def test_retina_head_forward():
    """Test RetinaNet Head forward in torch and onnxruntime env."""
    retina_model = retinanet_config()
    s = 128
    feats = [torch.rand(1, retina_model.in_channels, s // 2 ** (i + 2), s // 2 ** (i + 2)) for i in range(len(retina_model.prior_generator.strides))]
    ort_validate(retina_model.forward, feats)

def test_retinanet_head_onnx_export():
    """Test RetinaNet Head _get_bboxes() in torch and onnxruntime env."""
    retina_model = retinanet_config()
    s = 128
    img_metas = [{'img_shape_for_onnx': torch.Tensor([s, s]), 'scale_factor': np.ones(4), 'pad_shape': (s, s, 3), 'img_shape': (s, s, 2)}]
    retina_head_data = 'retina_head_get_bboxes.pkl'
    feats = mmcv.load(osp.join(data_path, retina_head_data))
    cls_score = feats[:5]
    bboxes = feats[5:]
    retina_model.onnx_export = partial(retina_model.onnx_export, img_metas=img_metas, with_nms=False)
    ort_validate(retina_model.onnx_export, (cls_score, bboxes))

def test_yolov3_head_forward():
    """Test Yolov3 head forward() in torch and ort env."""
    yolo_model = yolo_config()
    feats = [torch.rand(1, 1, 64 // 2 ** (i + 2), 64 // 2 ** (i + 2)) for i in range(len(yolo_model.in_channels))]
    ort_validate(yolo_model.forward, feats)

def yolo_config():
    """YoloV3 Head Config."""
    head_cfg = dict(anchor_generator=dict(type='YOLOAnchorGenerator', base_sizes=[[(116, 90), (156, 198), (373, 326)], [(30, 61), (62, 45), (59, 119)], [(10, 13), (16, 30), (33, 23)]], strides=[32, 16, 8]), bbox_coder=dict(type='YOLOBBoxCoder'))
    test_cfg = mmcv.Config(dict(deploy_nms_pre=0, min_bbox_size=0, score_thr=0.05, conf_thr=0.005, nms=dict(type='nms', iou_threshold=0.45), max_per_img=100))
    model = YOLOV3Head(num_classes=4, in_channels=[1, 1, 1], out_channels=[16, 8, 4], test_cfg=test_cfg, **head_cfg)
    model.requires_grad_(False)
    model.cpu().eval()
    return model

def test_yolov3_head_onnx_export():
    """Test yolov3 head get_bboxes() in torch and ort env."""
    yolo_model = yolo_config()
    s = 128
    img_metas = [{'img_shape_for_onnx': torch.Tensor([s, s]), 'img_shape': (s, s, 3), 'scale_factor': np.ones(4), 'pad_shape': (s, s, 3)}]
    yolo_head_data = 'yolov3_head_get_bboxes.pkl'
    pred_maps = mmcv.load(osp.join(data_path, yolo_head_data))
    yolo_model.onnx_export = partial(yolo_model.onnx_export, img_metas=img_metas, with_nms=False)
    ort_validate(yolo_model.onnx_export, pred_maps)

def test_fcos_head_forward_single():
    """Test fcos forward single in torch and ort env."""
    fcos_model = fcos_config()
    feat = torch.rand(1, fcos_model.in_channels, 32, 32)
    fcos_model.forward_single = partial(fcos_model.forward_single, scale=Scale(1.0).requires_grad_(False), stride=(4,))
    ort_validate(fcos_model.forward_single, feat)

def fcos_config():
    """FCOS Head Config."""
    test_cfg = mmcv.Config(dict(deploy_nms_pre=0, min_bbox_size=0, score_thr=0.05, nms=dict(type='nms', iou_threshold=0.5), max_per_img=100))
    model = FCOSHead(num_classes=4, in_channels=1, test_cfg=test_cfg)
    model.requires_grad_(False)
    return model

def test_fcos_head_forward():
    """Test fcos forward in mutil-level feature map."""
    fcos_model = fcos_config()
    s = 128
    feats = [torch.rand(1, 1, s // feat_size, s // feat_size) for feat_size in [4, 8, 16, 32, 64]]
    ort_validate(fcos_model.forward, feats)

def test_fcos_head_onnx_export():
    """Test fcos head get_bboxes() in ort."""
    fcos_model = fcos_config()
    s = 128
    img_metas = [{'img_shape_for_onnx': torch.Tensor([s, s]), 'img_shape': (s, s, 3), 'scale_factor': np.ones(4), 'pad_shape': (s, s, 3)}]
    cls_scores = [torch.rand(1, fcos_model.num_classes, s // feat_size, s // feat_size) for feat_size in [4, 8, 16, 32, 64]]
    bboxes = [torch.rand(1, 4, s // feat_size, s // feat_size) for feat_size in [4, 8, 16, 32, 64]]
    centerness = [torch.rand(1, 1, s // feat_size, s // feat_size) for feat_size in [4, 8, 16, 32, 64]]
    fcos_model.onnx_export = partial(fcos_model.onnx_export, img_metas=img_metas, with_nms=False)
    ort_validate(fcos_model.onnx_export, (cls_scores, bboxes, centerness))

def test_fsaf_head_forward_single():
    """Test RetinaNet Head forward_single() in torch and onnxruntime env."""
    fsaf_model = fsaf_config()
    feat = torch.rand(1, fsaf_model.in_channels, 32, 32)
    ort_validate(fsaf_model.forward_single, feat)

def fsaf_config():
    """FSAF Head Config."""
    cfg = dict(anchor_generator=dict(type='AnchorGenerator', octave_base_scale=1, scales_per_octave=1, ratios=[1.0], strides=[8, 16, 32, 64, 128]))
    test_cfg = mmcv.Config(dict(deploy_nms_pre=0, min_bbox_size=0, score_thr=0.05, nms=dict(type='nms', iou_threshold=0.5), max_per_img=100))
    model = FSAFHead(num_classes=4, in_channels=1, test_cfg=test_cfg, **cfg)
    model.requires_grad_(False)
    return model

def test_fsaf_head_forward():
    """Test RetinaNet Head forward in torch and onnxruntime env."""
    fsaf_model = fsaf_config()
    s = 128
    feats = [torch.rand(1, fsaf_model.in_channels, s // 2 ** (i + 2), s // 2 ** (i + 2)) for i in range(len(fsaf_model.anchor_generator.strides))]
    ort_validate(fsaf_model.forward, feats)

def test_fsaf_head_onnx_export():
    """Test RetinaNet Head get_bboxes in torch and onnxruntime env."""
    fsaf_model = fsaf_config()
    s = 256
    img_metas = [{'img_shape_for_onnx': torch.Tensor([s, s]), 'scale_factor': np.ones(4), 'pad_shape': (s, s, 3), 'img_shape': (s, s, 2)}]
    fsaf_head_data = 'fsaf_head_get_bboxes.pkl'
    feats = mmcv.load(osp.join(data_path, fsaf_head_data))
    cls_score = feats[:5]
    bboxes = feats[5:]
    fsaf_model.onnx_export = partial(fsaf_model.onnx_export, img_metas=img_metas, with_nms=False)
    ort_validate(fsaf_model.onnx_export, (cls_score, bboxes))

def test_ssd_head_forward():
    """Test SSD Head forward in torch and onnxruntime env."""
    ssd_model = ssd_config()
    featmap_size = [38, 19, 10, 6, 5, 3, 1]
    feats = [torch.rand(1, ssd_model.in_channels[i], featmap_size[i], featmap_size[i]) for i in range(len(ssd_model.in_channels))]
    ort_validate(ssd_model.forward, feats)

def ssd_config():
    """SSD Head Config."""
    cfg = dict(anchor_generator=dict(type='SSDAnchorGenerator', scale_major=False, input_size=300, basesize_ratio_range=(0.15, 0.9), strides=[8, 16, 32, 64, 100, 300], ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]]), bbox_coder=dict(type='DeltaXYWHBBoxCoder', target_means=[0.0, 0.0, 0.0, 0.0], target_stds=[0.1, 0.1, 0.2, 0.2]))
    test_cfg = mmcv.Config(dict(deploy_nms_pre=0, nms=dict(type='nms', iou_threshold=0.45), min_bbox_size=0, score_thr=0.02, max_per_img=200))
    model = SSDHead(num_classes=4, in_channels=(4, 8, 4, 2, 2, 2), test_cfg=test_cfg, **cfg)
    model.requires_grad_(False)
    return model

def test_ssd_head_onnx_export():
    """Test SSD Head get_bboxes in torch and onnxruntime env."""
    ssd_model = ssd_config()
    s = 300
    img_metas = [{'img_shape_for_onnx': torch.Tensor([s, s]), 'scale_factor': np.ones(4), 'pad_shape': (s, s, 3), 'img_shape': (s, s, 2)}]
    ssd_head_data = 'ssd_head_get_bboxes.pkl'
    feats = mmcv.load(osp.join(data_path, ssd_head_data))
    cls_score = feats[:6]
    bboxes = feats[6:]
    ssd_model.onnx_export = partial(ssd_model.onnx_export, img_metas=img_metas, with_nms=False)
    ort_validate(ssd_model.onnx_export, (cls_score, bboxes))

